import numpy as np
import pandas as pd
import pickle
import joblib
from sklearn.feature_selection import SelectKBest
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import chi2
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import recall_score, precision_score, accuracy_score

ModelDict = {}
TrainDict = {}
TestDict = {}
HyperparamsDict = {}

DataPath = "../Data/"
ModelPath = "../Data/Model/"

def get_mean_std(x_features, y_feature, data, train_fraction = 0.8):
    
    nTrain = int( data.shape[0] * train_fraction )
    
    train_df = data.iloc[:nTrain]
    test_df = data.iloc[nTrain:]
    
#     print(train_df)
#     print(test_df)

    mu = np.mean(train_df[x_features], axis=0)
    std = np.std(train_df[x_features], axis=0)
    std[std==0] = 1
    
    return mu, std


def get_mutual_info_score(X, y):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    score = mutual_info_classif(X, y, random_state=0)
    return score

def pcaFit(X, components):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
    
    pca = PCA(n_components = components)
    pca = pca.fit(X)
    return pca

def pcaTransform(X, pca):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
    
    X_pca = pca.transform(X)
    return X_pca

def TrainFunction(X, y, algo, dataset, selector, selector_params, featSelect):
    
    pipe = Pipeline([('featureSelector', selector),
              ('classifier', ModelDict[algo])])
    
    search_space = {**selector_params , **HyperparamsDict[algo]}
    
    print(search_space)
    
    cv_method = StratifiedKFold(n_splits=3)
    
    clf = GridSearchCV(pipe, search_space, scoring = "accuracy", cv=cv_method, n_jobs=4)
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    clf = clf.fit(X, y)
    
    print(clf.best_params_)
    
    res_df = pd.DataFrame(clf.cv_results_)
    res_df.to_excel(DataPath + dataset + "_" + featSelect + "_" + algo + "_results.xlsx", index=False)
    
    bestModel = clf.best_estimator_
    
    return bestModel

def TestFunction(X, model):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
    
    yPred = model.predict(X)
    
    return yPred




## --------------------- Model Code Below ---------------------- 

def LogisticRegressionTrain(X, y, bestHyperparams = None):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    print("Best Hyperparameters: ", bestHyperparams)
    
    logReg = LogisticRegression(bestHyperparams["classifier__C"])
    
    model = logReg.fit(X, y)
    
    return model

def LogisticRegressionTest(model, X):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
        
    yPred = model.predict(X)
    return yPred

ModelDict["LR"] = LogisticRegression()
TrainDict["LR"] = LogisticRegressionTrain
TestDict["LR"] = LogisticRegressionTest
HyperparamsDict["LR"] = {'classifier__C': [0.01, 0.1, 1.0]} 

def DecisionTreeTrain(X, y, bestHyperparams = None):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    print("Best Hyperparameters: ", bestHyperparams)
    
    dt = DecisionTreeClassifier(max_depth = bestHyperparams["classifier__max_depth"], random_state=42)
    
    model = dt.fit(X, y)
    
    return model

def DecisionTreeTest(model, X):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
        
    yPred = model.predict(X)
    return yPred

ModelDict["DT"] = DecisionTreeClassifier(random_state=42)
TrainDict["DT"] = DecisionTreeTrain
TestDict["DT"] = DecisionTreeTest
HyperparamsDict["DT"] = {'classifier__max_depth': [1,2,5,10,15,20]}

def RFTrain(X, y, bestHyperparams = None):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    print("Best Hyperparameters: ", bestHyperparams)
    
    dt = RandomForestClassifier(max_depth = bestHyperparams["classifier__max_depth"],\
                                n_estimators = bestHyperparams["classifier__n_estimators"], random_state=42)
    
    model = dt.fit(X, y)
    
    return model

def RFTest(model, X):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
        
    yPred = model.predict(X)
    return yPred

ModelDict["RF"] = RandomForestClassifier(random_state=42)
TrainDict["RF"] = RFTrain
TestDict["RF"] = RFTest
HyperparamsDict["RF"] = {'classifier__max_depth': [1,2,5,10,15,20], 'classifier__n_estimators': [100, 125, 150, 200]}


## SVC
def SVCTrain(X, y, bestHyperparams = None):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    print("Best Hyperparameters: ", bestHyperparams)
    
    supVec = SVC(C = bestHyperparams["classifier__C"], kernel = bestHyperparams["classifier__kernel"],\
             gamma = bestHyperparams["classifier__gamma"])
    
    model = supVec.fit(X, y)
    
    return model

def SVCTest(model, X):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
        
    yPred = model.predict(X)
    return yPred

ModelDict["SVC"] = SVC()
TrainDict["SVC"] = SVCTrain
TestDict["SVC"] = SVCTest
HyperparamsDict["SVC"] = {'classifier__C': [0.1, 1, 10, 100], 'classifier__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\
                          'classifier__kernel': ['rbf']}


## KNN
def KNNTrain(X, y, bestHyperparams = None):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()

    if type(y) != np.ndarray:
        y = y.to_numpy()
        
    y = y.reshape(-1)
    
    print("Best Hyperparameters: ", bestHyperparams)
    
    nearestNeighbors = KNeighborsClassifier(n_neighbors = bestHyperparams["classifier__n_neighbors"],\
                                            weights = bestHyperparams["classifier__weights"])
    
    model = nearestNeighbors.fit(X, y)
    
    return model

def KNNTest(model, X):
    
    if type(X) != np.ndarray:
        X = X.to_numpy()
        
    yPred = model.predict(X)
    return yPred

ModelDict["KNN"] = KNeighborsClassifier()
TrainDict["KNN"] = KNNTrain
TestDict["KNN"] = KNNTest
HyperparamsDict["KNN"] = {'classifier__n_neighbors': [1, 2, 5, 10, 15],
                          'classifier__weights': ['uniform', 'distance']}
    
